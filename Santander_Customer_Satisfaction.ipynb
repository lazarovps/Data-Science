{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Santander Customer Satisfaction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNymViW8zhp3tW6XY8RSBCb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lazarovps/Data-Science/blob/main/Santander_Customer_Satisfaction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuW6Xhj9bugi"
      },
      "source": [
        "#Santander Customer Satisfaction - Previsão de Churn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri0vcQZqdfQ-"
      },
      "source": [
        "Um dos problemas enfrentados por empresas que oferecem serviços com cobrança periodíca é o cancelamento do serviço, conhecido com \"churn\", que afeta a capacidade de faturamento da empresa no curto e longo prazo. \n",
        "Com base nisso, é desejável para qualquer empresa prever quem são os clientes mais propensos à churn, para que possa tentar entender a dor desse cliente e se possível fazê-lo ficar, evitando assim a perda de receita.\n",
        "\n",
        "Esse trabalho pretende, através de Machine Learning, prever quais são os possíveis clientes que irão \"churnar\" com a empresa em um período próximo.\n",
        "Esse case foi baseado no desafio posto no Kaggle pelo Banco Santander para a identificação dos clientes insatisfeitos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97boTnVUf6d0"
      },
      "source": [
        "#Importação das bibliotecas principais e dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deFgtXt4OndO",
        "outputId": "a3908664-188c-4dae-fbad-95ae9628aa58"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from google.colab import drive \n",
        "warnings.filterwarnings(\"ignore\")\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Python\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gblG9krsWI1Z"
      },
      "source": [
        "train = pd.read_csv('train_santander.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y19eik8vgH2z"
      },
      "source": [
        "#Análise exploratória e manipulação dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GQA4xeVWXrO",
        "outputId": "5ce84939-bcf2-4e31-e370-168a3c3ce579"
      },
      "source": [
        "train.shape\n",
        "#A base de dados (dataset) possui 76 mil linhas e 371 colunas"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76020, 371)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "zgTwGQs-QCnB",
        "outputId": "af97315a-34ec-4ee2-e718-aa9b590dc87f"
      },
      "source": [
        "#visualização das 3 primeiras linhas do dataset\n",
        "train.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>var3</th>\n",
              "      <th>var15</th>\n",
              "      <th>imp_ent_var16_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult3</th>\n",
              "      <th>imp_op_var40_comer_ult1</th>\n",
              "      <th>imp_op_var40_comer_ult3</th>\n",
              "      <th>imp_op_var40_efect_ult1</th>\n",
              "      <th>imp_op_var40_efect_ult3</th>\n",
              "      <th>imp_op_var40_ult1</th>\n",
              "      <th>imp_op_var41_comer_ult1</th>\n",
              "      <th>imp_op_var41_comer_ult3</th>\n",
              "      <th>imp_op_var41_efect_ult1</th>\n",
              "      <th>imp_op_var41_efect_ult3</th>\n",
              "      <th>imp_op_var41_ult1</th>\n",
              "      <th>imp_op_var39_efect_ult1</th>\n",
              "      <th>imp_op_var39_efect_ult3</th>\n",
              "      <th>imp_op_var39_ult1</th>\n",
              "      <th>imp_sal_var16_ult1</th>\n",
              "      <th>ind_var1_0</th>\n",
              "      <th>ind_var1</th>\n",
              "      <th>ind_var2_0</th>\n",
              "      <th>ind_var2</th>\n",
              "      <th>ind_var5_0</th>\n",
              "      <th>ind_var5</th>\n",
              "      <th>ind_var6_0</th>\n",
              "      <th>ind_var6</th>\n",
              "      <th>ind_var8_0</th>\n",
              "      <th>ind_var8</th>\n",
              "      <th>ind_var12_0</th>\n",
              "      <th>ind_var12</th>\n",
              "      <th>ind_var13_0</th>\n",
              "      <th>ind_var13_corto_0</th>\n",
              "      <th>ind_var13_corto</th>\n",
              "      <th>ind_var13_largo_0</th>\n",
              "      <th>ind_var13_largo</th>\n",
              "      <th>ind_var13_medio_0</th>\n",
              "      <th>ind_var13_medio</th>\n",
              "      <th>ind_var13</th>\n",
              "      <th>...</th>\n",
              "      <th>saldo_medio_var5_ult1</th>\n",
              "      <th>saldo_medio_var5_ult3</th>\n",
              "      <th>saldo_medio_var8_hace2</th>\n",
              "      <th>saldo_medio_var8_hace3</th>\n",
              "      <th>saldo_medio_var8_ult1</th>\n",
              "      <th>saldo_medio_var8_ult3</th>\n",
              "      <th>saldo_medio_var12_hace2</th>\n",
              "      <th>saldo_medio_var12_hace3</th>\n",
              "      <th>saldo_medio_var12_ult1</th>\n",
              "      <th>saldo_medio_var12_ult3</th>\n",
              "      <th>saldo_medio_var13_corto_hace2</th>\n",
              "      <th>saldo_medio_var13_corto_hace3</th>\n",
              "      <th>saldo_medio_var13_corto_ult1</th>\n",
              "      <th>saldo_medio_var13_corto_ult3</th>\n",
              "      <th>saldo_medio_var13_largo_hace2</th>\n",
              "      <th>saldo_medio_var13_largo_hace3</th>\n",
              "      <th>saldo_medio_var13_largo_ult1</th>\n",
              "      <th>saldo_medio_var13_largo_ult3</th>\n",
              "      <th>saldo_medio_var13_medio_hace2</th>\n",
              "      <th>saldo_medio_var13_medio_hace3</th>\n",
              "      <th>saldo_medio_var13_medio_ult1</th>\n",
              "      <th>saldo_medio_var13_medio_ult3</th>\n",
              "      <th>saldo_medio_var17_hace2</th>\n",
              "      <th>saldo_medio_var17_hace3</th>\n",
              "      <th>saldo_medio_var17_ult1</th>\n",
              "      <th>saldo_medio_var17_ult3</th>\n",
              "      <th>saldo_medio_var29_hace2</th>\n",
              "      <th>saldo_medio_var29_hace3</th>\n",
              "      <th>saldo_medio_var29_ult1</th>\n",
              "      <th>saldo_medio_var29_ult3</th>\n",
              "      <th>saldo_medio_var33_hace2</th>\n",
              "      <th>saldo_medio_var33_hace3</th>\n",
              "      <th>saldo_medio_var33_ult1</th>\n",
              "      <th>saldo_medio_var33_ult3</th>\n",
              "      <th>saldo_medio_var44_hace2</th>\n",
              "      <th>saldo_medio_var44_hace3</th>\n",
              "      <th>saldo_medio_var44_ult1</th>\n",
              "      <th>saldo_medio_var44_ult3</th>\n",
              "      <th>var38</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39205.17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>122.22</td>\n",
              "      <td>300.0</td>\n",
              "      <td>240.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49278.03</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67333.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 371 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  var3  var15  ...  saldo_medio_var44_ult3     var38  TARGET\n",
              "0   1     2     23  ...                     0.0  39205.17       0\n",
              "1   3     2     34  ...                     0.0  49278.03       0\n",
              "2   4     2     23  ...                     0.0  67333.77       0\n",
              "\n",
              "[3 rows x 371 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtWGvOF_QE2-"
      },
      "source": [
        "#Separação da variável alvo (TARGET) das variáveis preditoras\n",
        "y_train = train[['TARGET']]\n",
        "train = train.drop('TARGET', axis = 1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "oBQXnavMW6O1",
        "outputId": "b67b30a5-a786-4103-eb9c-10dfd75da1db"
      },
      "source": [
        "train.describe().T"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <td>76020.0</td>\n",
              "      <td>75964.050723</td>\n",
              "      <td>43781.947379</td>\n",
              "      <td>1.00</td>\n",
              "      <td>38104.7500</td>\n",
              "      <td>76043.00</td>\n",
              "      <td>113748.7500</td>\n",
              "      <td>151838.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>var3</th>\n",
              "      <td>76020.0</td>\n",
              "      <td>-1523.199277</td>\n",
              "      <td>39033.462364</td>\n",
              "      <td>-999999.00</td>\n",
              "      <td>2.0000</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.0000</td>\n",
              "      <td>238.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>var15</th>\n",
              "      <td>76020.0</td>\n",
              "      <td>33.212865</td>\n",
              "      <td>12.956486</td>\n",
              "      <td>5.00</td>\n",
              "      <td>23.0000</td>\n",
              "      <td>28.00</td>\n",
              "      <td>40.0000</td>\n",
              "      <td>105.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imp_ent_var16_ult1</th>\n",
              "      <td>76020.0</td>\n",
              "      <td>86.208265</td>\n",
              "      <td>1614.757313</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>210000.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imp_op_var39_comer_ult1</th>\n",
              "      <td>76020.0</td>\n",
              "      <td>72.363067</td>\n",
              "      <td>339.315831</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>12888.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>saldo_medio_var44_hace2</th>\n",
              "      <td>76020.0</td>\n",
              "      <td>31.505324</td>\n",
              "      <td>2013.125393</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>438329.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>saldo_medio_var44_hace3</th>\n",
              "      <td>76020.0</td>\n",
              "      <td>1.858575</td>\n",
              "      <td>147.786584</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>24650.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>saldo_medio_var44_ult1</th>\n",
              "      <td>76020.0</td>\n",
              "      <td>76.026165</td>\n",
              "      <td>4040.337842</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>681462.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>saldo_medio_var44_ult3</th>\n",
              "      <td>76020.0</td>\n",
              "      <td>56.614351</td>\n",
              "      <td>2852.579397</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>397884.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>var38</th>\n",
              "      <td>76020.0</td>\n",
              "      <td>117235.809430</td>\n",
              "      <td>182664.598503</td>\n",
              "      <td>5163.75</td>\n",
              "      <td>67870.6125</td>\n",
              "      <td>106409.16</td>\n",
              "      <td>118756.2525</td>\n",
              "      <td>22034738.76</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>370 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           count           mean  ...          75%          max\n",
              "ID                       76020.0   75964.050723  ...  113748.7500    151838.00\n",
              "var3                     76020.0   -1523.199277  ...       2.0000       238.00\n",
              "var15                    76020.0      33.212865  ...      40.0000       105.00\n",
              "imp_ent_var16_ult1       76020.0      86.208265  ...       0.0000    210000.00\n",
              "imp_op_var39_comer_ult1  76020.0      72.363067  ...       0.0000     12888.03\n",
              "...                          ...            ...  ...          ...          ...\n",
              "saldo_medio_var44_hace2  76020.0      31.505324  ...       0.0000    438329.22\n",
              "saldo_medio_var44_hace3  76020.0       1.858575  ...       0.0000     24650.01\n",
              "saldo_medio_var44_ult1   76020.0      76.026165  ...       0.0000    681462.90\n",
              "saldo_medio_var44_ult3   76020.0      56.614351  ...       0.0000    397884.30\n",
              "var38                    76020.0  117235.809430  ...  118756.2525  22034738.76\n",
              "\n",
              "[370 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq8H7mEtg0ia"
      },
      "source": [
        "Ao verificar as estatísticas descritivas das variáveis, percebe-se que a variável \"var3\" está com valores mínimos de -999999, o que provavelmente representa valores nulos, para evitar problemas nos modelos, iremos substituir todos os valores que estiverem assim por 0, diminuindo o impacto desses no resultado final.\n",
        "\n",
        "Além disso, iremos remover a coluna 'ID', já que essa é apenas uma forma de identificação de cada indivíduo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_02bMCflTM1I"
      },
      "source": [
        "train = train.replace(-999999,0)\n",
        "train = train.drop('ID', axis = 1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS6tshIRXieu",
        "outputId": "dce28ac0-9dbe-4725-fee8-a043985ef023"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 76020 entries, 0 to 76019\n",
            "Columns: 369 entries, var3 to var38\n",
            "dtypes: float64(111), int64(258)\n",
            "memory usage: 214.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SXaV3tjUnyX"
      },
      "source": [
        "Ao olharmos o dtype, percebemos que há 111 variáveis do tipo flutuantes e 258 do tipo inteiro. Portanto, não temos a necessidade de fazer transformação de variáveis categóricas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "j03B8v5SZZYh",
        "outputId": "8d5ca05b-b96f-48ca-96e3-8c0dcba0d148"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76015</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76016</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76017</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76018</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76019</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76020 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       TARGET\n",
              "0           0\n",
              "1           0\n",
              "2           0\n",
              "3           0\n",
              "4           0\n",
              "...       ...\n",
              "76015       0\n",
              "76016       0\n",
              "76017       0\n",
              "76018       0\n",
              "76019       0\n",
              "\n",
              "[76020 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "KwsiENozYMYg",
        "outputId": "3b166e50-0aa0-42f2-b511-ffe1ec3293a8"
      },
      "source": [
        "sns.countplot( x= 'TARGET', data = y_train, palette = 'Set1')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd1f1475990>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD0u9E36bi18",
        "outputId": "fc006131-c885-4357-94c0-191a9307dd00"
      },
      "source": [
        "y_train['TARGET'].value_counts(normalize = True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.960431\n",
              "1    0.039569\n",
              "Name: TARGET, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBP0jKEPkV0v",
        "outputId": "abfedbb0-4d11-4855-b106-81dc0c15ec6a"
      },
      "source": [
        "y_train['TARGET'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    73012\n",
              "1     3008\n",
              "Name: TARGET, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnLFFtYgiagf"
      },
      "source": [
        "Verificando a distribuição da variável alvo percebemos que o dataset está muito desbalanceado, com indivíduos que não deram churn em 96% dos dados, nesses casos, antes de modelarmos, é extremamente necessário deixar os dados balanceados, para que o nosso modelo não tenda à prever de maneira equivocada.\n",
        "\n",
        "Para balancear os dados, iremos utilizar a técnica Synthetic Minority Oversampling Technique (SMOTE), que gera nova instâncias de dados a partir da proximidade das variáveis de dados semelhantes. Essa técnica está presente no pacote imblearn.\n",
        "\n",
        "O único argumento que iremos utilizar é o \"sampling_strategy\" que representa a razão que queremos da classe minoritária sobre a classe majoritária, escolhendo a razão de 0.50, significa que a quantidade de exemplos da classe minoritária será 50% da classe majoritária (atualmente esse valor é de 4 %)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ve3zszVYqvm"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(sampling_strategy=0.50)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4MWeexJYyiU"
      },
      "source": [
        "x_train, y_train = smote.fit_resample(train,y_train)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItS2Ot2PlIjU",
        "outputId": "96a4069a-d439-444e-c1e6-04b1adfe3816"
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((109518, 369), (109518,))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TD3A92-VQY7"
      },
      "source": [
        "Percebemos que agora nosso dataset possui mais de 109 mil observações, ou seja, geramos 33 mil \"individuos sinteticos\", todos com a variável alvo igual a 1. Agora, temos 36 mil que \"churnaram\" contra 73 mil que não \"churnaram\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87GuZR01ZUDJ",
        "outputId": "e48701c7-1264-4115-d9da-cd6c5313aed0"
      },
      "source": [
        "y_train.sum()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36506"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUAyTZN4kzDY"
      },
      "source": [
        "Além desse procedimento, podemos eliminar alguns dados da classe majoritária. Esse método não é muito indicado quando há poucos dados, já que estaremos perdendo informação, mas nesse caso é aplicável. A forma que vamos eliminar os exemplos será aleatória, com o Random Under Sampler, também do imblearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMOHqMWZ7nwE"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "rus = RandomUnderSampler(sampling_strategy = 0.90, random_state = 12)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6agW2PdfrUgG"
      },
      "source": [
        "Para preservar o máximo de informação possível, podemos fazer com que a classe minoritária seja 90% da classe majoritária, essa diferença não prejudicará os resultados do modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ac_mJZgcn4Z"
      },
      "source": [
        "x_train,y_train = rus.fit_resample(x_train,y_train)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow71WqbyrthJ",
        "outputId": "6ae28e77-cd45-4345-fa02-29541daf89e2"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(77068, 369)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypc5te7hr2Xr"
      },
      "source": [
        "Agora possuimos 77 mil individuos, mas dessa vez as classes estão quase qu perfeitamente balanceadas.\n",
        "\n",
        "Após isso, podemos dividir entre dados em treino e validação, onde o conjunto de treino serve para o algoritmo aprender os padrões das variáveis e o conjunto de validação, como o nome sugere, serve para avaliarmos se o algoritmo \"aprendeu bem\". \n",
        "\n",
        "A divisão será em 70% dados de treino e 30% dados de validação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-CK8c0CPhK5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split as tts\n",
        "x_train, x_valid, y_train, y_valid = tts(x_train,y_train, test_size = 0.30, random_state = 12)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7Geq1_TQbsw",
        "outputId": "6dd37c0f-de2a-458b-f472-1b21981dd67f"
      },
      "source": [
        "x_train.shape, x_valid.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((53947, 369), (23121, 369))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SrsYIgW2AND",
        "outputId": "780fdf64-e6a2-4662-a275-210a03e4a617"
      },
      "source": [
        "y_train.shape, y_valid.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((53947,), (23121,))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Thlkq9plshHB"
      },
      "source": [
        "Após a divisão, iremos padronizar as variáveis, deixando todas na mesma escala, já que a escala inapropriada das variáveis acaba afetando negativamente os resultados de muitos algoritmos de Machine Learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyMAaXwB4ibq"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v175-LH472L2"
      },
      "source": [
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_valid_scaled = scaler.transform(x_valid)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxBOSC9oMoYW"
      },
      "source": [
        "#Seleção das variáveis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zplam_AG-GTb"
      },
      "source": [
        "Após a padronização podemos começar o processo de seleção das variáveis, por possuir mais de 360, é provável que muitas dessas sejam bastante correlacionadas, o que também prejudica o aprendizado da máquina, para evitar isso podemos fazer uma seleção das melhores variáveis de acordo com algum critério.\n",
        "\n",
        "O método que foi pensado para essa seleção será o Principal Components Analysis(PCA), basicamente, ele procura reduzir a dimensionalidade de um conjunto de dados mantendo a maior quantidade de informação (variância dos dados) possível. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdkCMtYj9oq7"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcziGCti90Xg",
        "outputId": "f158b9bf-4470-49dd-b062-265a47de6266"
      },
      "source": [
        "pca.fit(x_train_scaled)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
              "    svd_solver='auto', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So8gkh0XHM5M"
      },
      "source": [
        "Ao fitarmos o algoritmo, teremos um valor para cada uma das dimensões, esse valor representa o quanto aquela dimensão explica a variância do conjunto de dados, então, queremos manter as dimensões que mais explicam a variância. o método \"explained_variance_ratio_\" ordena esses valores do maior para menor, e sua soma será 1 (ou 100%)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2POWGeHqGzB1",
        "outputId": "c0256198-2fd1-49b7-c746-1edcfc4b0f36"
      },
      "source": [
        "pca.explained_variance_ratio_"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.35588655e-02, 5.28809617e-02, 4.07535519e-02, 3.68942818e-02,\n",
              "       3.62399225e-02, 3.53587911e-02, 3.20670909e-02, 3.14342677e-02,\n",
              "       2.88217397e-02, 2.77829234e-02, 2.47108114e-02, 2.33295680e-02,\n",
              "       2.16500230e-02, 2.06348341e-02, 1.69014688e-02, 1.56170739e-02,\n",
              "       1.44673537e-02, 1.36254043e-02, 1.32379534e-02, 1.31109716e-02,\n",
              "       1.28261584e-02, 1.23551548e-02, 1.23056977e-02, 1.19489867e-02,\n",
              "       1.11845031e-02, 1.10323208e-02, 1.02276314e-02, 1.01732678e-02,\n",
              "       9.94456268e-03, 9.65964660e-03, 9.35362281e-03, 9.10623929e-03,\n",
              "       9.02246945e-03, 8.81232176e-03, 8.66635675e-03, 7.96674334e-03,\n",
              "       7.19013777e-03, 6.91602337e-03, 6.81838490e-03, 6.65558990e-03,\n",
              "       6.62681035e-03, 6.36196975e-03, 6.14449836e-03, 5.91180383e-03,\n",
              "       5.85503049e-03, 5.67688971e-03, 5.59795575e-03, 5.18409360e-03,\n",
              "       5.10058220e-03, 4.84611938e-03, 4.71374019e-03, 4.55959928e-03,\n",
              "       4.46638181e-03, 4.38190199e-03, 4.18000396e-03, 3.88773996e-03,\n",
              "       3.73050786e-03, 3.64580519e-03, 3.57273213e-03, 3.45385227e-03,\n",
              "       3.38585310e-03, 3.17733580e-03, 3.08253765e-03, 3.02727043e-03,\n",
              "       2.98885907e-03, 2.94714345e-03, 2.89566896e-03, 2.85411029e-03,\n",
              "       2.79037520e-03, 2.71372618e-03, 2.68001341e-03, 2.57715152e-03,\n",
              "       2.50114569e-03, 2.43880950e-03, 2.40253122e-03, 2.30421186e-03,\n",
              "       2.26521145e-03, 2.22488832e-03, 2.14594048e-03, 2.09892291e-03,\n",
              "       2.07034722e-03, 2.04620280e-03, 1.93516330e-03, 1.91535351e-03,\n",
              "       1.87108946e-03, 1.83282922e-03, 1.74877651e-03, 1.68311490e-03,\n",
              "       1.60802850e-03, 1.57350904e-03, 1.56406571e-03, 1.53569197e-03,\n",
              "       1.41403324e-03, 1.36073971e-03, 1.26427165e-03, 1.22611933e-03,\n",
              "       1.19705284e-03, 1.18611539e-03, 1.14545449e-03, 1.14185730e-03,\n",
              "       1.08399692e-03, 1.05718415e-03, 1.03444648e-03, 1.02379787e-03,\n",
              "       9.74341092e-04, 9.43658278e-04, 9.15369838e-04, 8.98583327e-04,\n",
              "       8.85738219e-04, 8.78490491e-04, 8.65861823e-04, 8.29913471e-04,\n",
              "       7.62881329e-04, 7.46031686e-04, 7.27635872e-04, 6.73304112e-04,\n",
              "       6.63998631e-04, 6.56257026e-04, 6.35980803e-04, 6.22989685e-04,\n",
              "       6.14030642e-04, 6.09071998e-04, 5.84073579e-04, 5.80804466e-04,\n",
              "       5.72584309e-04, 5.56371490e-04, 5.07380133e-04, 4.81318654e-04,\n",
              "       4.73108897e-04, 4.57336415e-04, 4.45232627e-04, 4.30879259e-04,\n",
              "       4.09341683e-04, 3.95650994e-04, 3.64820315e-04, 3.41781448e-04,\n",
              "       3.27655695e-04, 3.07742444e-04, 3.02134843e-04, 2.88089050e-04,\n",
              "       2.79152439e-04, 2.75815428e-04, 2.52695699e-04, 2.44057351e-04,\n",
              "       2.42389837e-04, 2.29989675e-04, 2.23334963e-04, 2.12786716e-04,\n",
              "       2.09172720e-04, 2.02448411e-04, 1.96146101e-04, 1.93704647e-04,\n",
              "       1.91532759e-04, 1.89995715e-04, 1.83807043e-04, 1.65117722e-04,\n",
              "       1.61228811e-04, 1.55528011e-04, 1.42680902e-04, 1.41851467e-04,\n",
              "       1.38402378e-04, 1.24534107e-04, 1.20468668e-04, 1.12382742e-04,\n",
              "       1.10482095e-04, 9.96406559e-05, 9.80615630e-05, 9.15034045e-05,\n",
              "       8.15005189e-05, 7.28096541e-05, 6.64592488e-05, 6.26750100e-05,\n",
              "       6.06143430e-05, 5.39967999e-05, 4.96557319e-05, 4.88018644e-05,\n",
              "       4.72906350e-05, 4.54659580e-05, 4.30123171e-05, 4.24454587e-05,\n",
              "       3.95683462e-05, 3.87766012e-05, 3.46499705e-05, 3.09117131e-05,\n",
              "       2.68081556e-05, 2.27105841e-05, 2.19710083e-05, 2.11884558e-05,\n",
              "       1.77269131e-05, 1.60011890e-05, 1.57239947e-05, 1.43178634e-05,\n",
              "       1.37119623e-05, 1.31630169e-05, 1.29560022e-05, 1.25806175e-05,\n",
              "       1.15757285e-05, 1.09755513e-05, 1.00015244e-05, 8.07959674e-06,\n",
              "       7.84356431e-06, 7.51273672e-06, 5.52126121e-06, 5.41949033e-06,\n",
              "       5.01988041e-06, 3.87005632e-06, 3.25623411e-06, 3.23011710e-06,\n",
              "       2.26303418e-06, 1.68159812e-06, 1.26379602e-06, 1.20345863e-06,\n",
              "       9.24985374e-07, 6.18908848e-07, 2.17279671e-07, 2.66892237e-08,\n",
              "       2.26543046e-24, 8.50627035e-25, 2.95085821e-25, 1.09037899e-30,\n",
              "       5.25869190e-31, 2.96355711e-32, 2.39756639e-32, 2.24199849e-32,\n",
              "       2.22102474e-32, 1.57203801e-32, 9.42228461e-33, 7.24443164e-33,\n",
              "       5.63119377e-33, 4.81774071e-33, 4.52599629e-33, 4.21654007e-33,\n",
              "       3.96986535e-33, 3.84979269e-33, 3.47772484e-33, 3.27338431e-33,\n",
              "       2.69922033e-33, 2.38663849e-33, 2.35645808e-33, 2.25006943e-33,\n",
              "       2.13626598e-33, 2.03071731e-33, 1.91225122e-33, 1.79119118e-33,\n",
              "       1.51545711e-33, 1.49438090e-33, 1.41992919e-33, 1.40409249e-33,\n",
              "       1.15768425e-33, 1.08275611e-33, 1.00157588e-33, 7.41792548e-34,\n",
              "       6.56018207e-34, 6.29396354e-34, 5.49001345e-34, 4.63117837e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.91303214e-34,\n",
              "       3.91303214e-34, 3.91303214e-34, 3.91303214e-34, 3.76245345e-34,\n",
              "       3.42526583e-34, 2.61732506e-34, 1.56508354e-34, 1.03578671e-34,\n",
              "       8.51315575e-35, 5.88016414e-35, 5.66480128e-35, 2.29737146e-35,\n",
              "       1.40167101e-36])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hNeKtVh-qiG",
        "outputId": "743ada08-651d-4df4-cc28-d745845b7738"
      },
      "source": [
        "np.sum(pca.explained_variance_ratio_)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999999999999999"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srxZI3iCIlSr"
      },
      "source": [
        "Para uma melhor intuição, podemos plotar o \"poder explicativo\" das 10 principais dimensões (ou componentes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGS11jnMDTWq"
      },
      "source": [
        "var_pca = pca.explained_variance_ratio_"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a03KU2CqN0yR"
      },
      "source": [
        "first_10 = np.arange(1,11)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "3iWZ_LtkOG95",
        "outputId": "e1351dcc-4faf-4dae-d066-12f69148eb0d"
      },
      "source": [
        "sns.barplot(x = first_10, y = var_pca[0:10])\n",
        "plt.title(\"Razão da variância explicada das 10 maiores componentes\\n\")\n",
        "plt.xlabel(\"Principais Componentes\")\n",
        "plt.ylabel(\"Razão da variância explicada\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Razão da variância explicada')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_fY0YRrI1gy"
      },
      "source": [
        "Com isso vemos que a componente 1 explica aproximadamente 9% da variância dos dados, a componente 2 explica 5 % e assim sucessivamente. O objetivo então, é manter o mínimo de componentes possível mas mantendo boa parte da explicação da variância"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIhrSLVgOVA4"
      },
      "source": [
        "pc = np.arange(10,210,10)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HkcpA9NOebq",
        "outputId": "457ac221-f7d2-45d3-b5dc-d9308c901dd6"
      },
      "source": [
        "for i in pc:\n",
        "  print(\"Com as {} maiores componentes, capta-se cerca de {} % da variância dos dados\".format(i,np.round((var_pca[0:i].sum()*100),2)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Com as 10 maiores componentes, capta-se cerca de 41.58 % da variância dos dados\n",
            "Com as 20 maiores componentes, capta-se cerca de 59.31 % da variância dos dados\n",
            "Com as 30 maiores componentes, capta-se cerca de 70.47 % da variância dos dados\n",
            "Com as 40 maiores componentes, capta-se cerca de 78.52 % da variância dos dados\n",
            "Com as 50 maiores componentes, capta-se cerca de 84.25 % da variância dos dados\n",
            "Com as 60 maiores componentes, capta-se cerca de 88.31 % da variância dos dados\n",
            "Com as 70 maiores componentes, capta-se cerca de 91.3 % da variância dos dados\n",
            "Com as 80 maiores componentes, capta-se cerca de 93.66 % da variância dos dados\n",
            "Com as 90 maiores componentes, capta-se cerca de 95.49 % da variância dos dados\n",
            "Com as 100 maiores componentes, capta-se cerca de 96.8 % da variância dos dados\n",
            "Com as 110 maiores componentes, capta-se cerca de 97.77 % da variância dos dados\n",
            "Com as 120 maiores componentes, capta-se cerca de 98.48 % da variância dos dados\n",
            "Com as 130 maiores componentes, capta-se cerca de 99.03 % da variância dos dados\n",
            "Com as 140 maiores componentes, capta-se cerca de 99.39 % da variância dos dados\n",
            "Com as 150 maiores componentes, capta-se cerca de 99.63 % da variância dos dados\n",
            "Com as 160 maiores componentes, capta-se cerca de 99.8 % da variância dos dados\n",
            "Com as 170 maiores componentes, capta-se cerca de 99.9 % da variância dos dados\n",
            "Com as 180 maiores componentes, capta-se cerca de 99.96 % da variância dos dados\n",
            "Com as 190 maiores componentes, capta-se cerca de 99.98 % da variância dos dados\n",
            "Com as 200 maiores componentes, capta-se cerca de 100.0 % da variância dos dados\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUCF02BtQult"
      },
      "source": [
        "Percebemos que o retorno marginal de 10 componentes a mais é cada vez menor, a fim de simplificar o máximo o conjunto de dados, podemos deixar apenas as 100 maiores componentes, que explicam aproximadamente 97% da variância dos dados.\n",
        "\n",
        "Então novamente fitamos o PCA, mas escolhendo 100 no argumento \"n_components\", dessa forma, todos os nossos dados serão representados em apenas 100 dimensões (tínhamos aproxidamente 370)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76fWQyEIRKDZ"
      },
      "source": [
        "pca = PCA(n_components=100)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgHWk2fwRO9r"
      },
      "source": [
        "x_pca_train = pca.fit_transform(x_train_scaled)\n",
        "x_pca_valid = pca.transform(x_valid_scaled)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxl2F5L8RdCT",
        "outputId": "00cb1304-288b-4f71-c1f0-3200594b66cf"
      },
      "source": [
        "x_pca_train.shape, x_pca_valid.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((53947, 100), (23121, 100))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi6I7gGMKMpM",
        "outputId": "f76fe3f6-bf1c-4006-8c78-3a30b12c86c4"
      },
      "source": [
        "x_pca_train"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.62197823e+00, -1.27542195e+00,  1.81145379e-01, ...,\n",
              "        -2.96580777e-02,  9.62482379e-03, -6.02559378e-02],\n",
              "       [-2.57074433e+00, -1.24322105e+00,  1.80554242e-01, ...,\n",
              "        -1.58888836e-01, -1.35440576e-01,  6.48386604e-02],\n",
              "       [-2.61930427e+00, -1.26578516e+00,  1.79127338e-01, ...,\n",
              "        -3.74122449e-02,  1.98472968e-02, -4.30906553e-02],\n",
              "       ...,\n",
              "       [-1.72354096e+00, -3.96442415e-01,  4.46661343e-02, ...,\n",
              "         4.64074275e-01, -2.95808446e-02,  2.94374553e-01],\n",
              "       [-3.20819245e+00, -1.66590610e+00,  3.61546606e-01, ...,\n",
              "        -4.25371341e-02,  1.51626459e-02, -8.03507168e-02],\n",
              "       [-2.52231148e+00, -1.13513366e+00,  1.71116062e-01, ...,\n",
              "         3.85537721e-04,  1.34705971e-01, -1.89806429e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfygr6eWKUOj"
      },
      "source": [
        "Um ponto negativo da redução de dimensionalidade é que as variáveis restantes não posssuem mais interpretação lógica.\n",
        "\n",
        "Após todo esse processo, podemos enfim tentar prever o Churn. Os modelos que serão utilizados são a Regressão Logística e a Random Forest Classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p0ymq4dMt5V"
      },
      "source": [
        "#Modelo 1 - Regressão Logística"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVwVPzO3W3fL"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "log = LogisticRegression()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg2YQ8CjXaIK",
        "outputId": "34f1f131-d446-486d-d873-99c538bb54c4"
      },
      "source": [
        "log.fit(x_pca_train,y_train)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJv_w8_XXc9W"
      },
      "source": [
        "y_predict_log = log.predict(x_pca_valid)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0yK_IAQNUqh"
      },
      "source": [
        "Ao fitarmos e prevermos os valores para os dados de validação, devemos escolher por qual métrica iremos olhar o resultado. As que serão utilizadas nesse caso serão:\n",
        "\n",
        "Precisão (Precision score) - pode ser entendida como a pergunta \"Dos exemplos que foram classificados como positivo (Churn), quantos realmente são?\"\n",
        "\n",
        "Revocação (Recall score) - Pode ser entendida pela pergunta \"Dos exemplos positivos (Churn), quantos foram previstos?\"\n",
        "\n",
        "F1 (F1 score) - essa métrica é uma ponderação das anteriores, ela é especificamente definida como 2 * ((precisão * revocação)/(precisão + revocação))\n",
        "\n",
        "Todas essas métricas estão no intervalo entre 0 e 1, onde 0 indica que nosso modelo não acerta nenhuma previsão e 1 (100%) que ele acerta todas. No fim, desejamos um valor suficiente próximo de 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoSa0iCObpue"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjTdLrhkyyfv"
      },
      "source": [
        "precision_log = precision_score(y_valid,y_predict_log)\n",
        "recall_log = recall_score(y_valid,y_predict_log)\n",
        "f1_log = f1_score(y_valid,y_predict_log)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgwIXH-5M01n"
      },
      "source": [
        "#Modelo 2 - Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJOhcKhdXjjn"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDIQ9sSRRRLX",
        "outputId": "dae503bc-101f-4378-f46d-c9db674777c2"
      },
      "source": [
        "rfc.fit(x_pca_train,y_train)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW4SmWsiaIvY"
      },
      "source": [
        "y_predict_rfc = rfc.predict(x_pca_valid)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8ZV9bdn8X9I"
      },
      "source": [
        "precision_rfc = precision_score(y_valid,y_predict_rfc)\n",
        "recall_rfc = recall_score(y_valid,y_predict_rfc)\n",
        "f1_rfc = f1_score(y_valid,y_predict_rfc)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnJ6EBI3M91G"
      },
      "source": [
        "#Resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMq5S5J9Qu_S"
      },
      "source": [
        "Enfim, podemos comparar o resultado dos 2 modelos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdhCcKaX8SLI",
        "outputId": "248cb2c1-1a8b-4e39-db94-79e28362ecf2"
      },
      "source": [
        "print(\"Resultados da Regressão Logística\\n\")\n",
        "print(\"Precision score:{}\".format(precision_log))\n",
        "print(\"Recall score:{}\".format(recall_log))\n",
        "print(\"F1 score:{}\\n\".format(f1_log))\n",
        "\n",
        "print(\"Resultados da Random Forest\\n\")\n",
        "print(\"Precision score:{}\".format(precision_rfc))\n",
        "print(\"Recall score:{}\".format(recall_rfc))\n",
        "print(\"F1 score:{}\".format(f1_rfc))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados da Regressão Logística\n",
            "\n",
            "Precision score:0.6984262016163335\n",
            "Recall score:0.7475188928343804\n",
            "F1 score:0.7221391503210485\n",
            "\n",
            "Resultados da Random Forest\n",
            "\n",
            "Precision score:0.9194369849060098\n",
            "Recall score:0.9040335063279614\n",
            "F1 score:0.9116701863924341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgeSeSvJQ3jh"
      },
      "source": [
        "Em todas as métricas observadas, os valores do algoritmo de Random Forest é maior que o de Regressão Logística, sugerindo que esse primeiro possui um maior poder preditivo.\n",
        "\n",
        "Finalmente iremos prever o Churn para os clientes dos dados de teste.\n",
        "\n",
        "Então, devemos transformar os dados da forma que fizemos com os dados de treino e de validação:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPtXO8tVkBJa"
      },
      "source": [
        "#Leitura dos dados\n",
        "x_test = pd.read_csv('test_santander.csv')\n",
        "\n",
        "#Substituição dos dados \"nulos\" por 0 e remoção da coluna 'ID\n",
        "x_test = x_test.replace(-999999,0)\n",
        "x_test = x_test.drop('ID', axis = 1)\n",
        "\n",
        "#Padronização e seleção das variáveis\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "x_pca_test = pca.transform(x_test_scaled)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcuJ3zRTWmLO"
      },
      "source": [
        "#Predição\n",
        "y_test_predict = rfc.predict(x_pca_test)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtgJtdEyW0xw",
        "outputId": "129a5844-a6bc-40b5-d3fc-e5de82285a07"
      },
      "source": [
        "y_test_predict.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75818,)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32St_8O4W6js",
        "outputId": "910ce3a6-92dc-4708-d612-9dcf375c4bb8"
      },
      "source": [
        "y_test_predict.sum()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6006"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb6_bbhjSRa1"
      },
      "source": [
        "Pelo fato de não termos os reais resultados para os dados de teste, não temos como utilizar as métricas definidas anteriormente para o avaliarmos, mas, esperamos que os resultados sejam semelhantes aos dados de validação. Podemos observar que dos aproximadamente 76 mil valores previstos, 6 mil foram previstos como clientes de potencial Churn, ficando à cargo do setor de Marketing, a tentativa de evitar isso."
      ]
    }
  ]
}